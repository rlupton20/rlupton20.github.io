<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Posts &middot; Pure Hack</title><meta name=description content><meta name=generator content="Hugo 0.59.0"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts &middot; Pure Hack"><meta name=twitter:description content><meta property="og:type" content="article"><meta property="og:title" content="Posts &middot; Pure Hack"><meta property="og:description" content><link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css><link rel=stylesheet href=https://rlupton20.github.io/css/all.min.css><link href=//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css rel=stylesheet><link rel=alternate type=application/rss+xml title="Pure Hack" href=https://rlupton20.github.io/index.xml></head><body><div id=layout class=pure-g><div class="sidebar pure-u-1 pure-u-md-1-4"><div class=header><hgroup><h1 class=brand-title><a href=https://rlupton20.github.io/>Pure Hack</a></h1><h2 class=brand-tagline></h2></hgroup><nav class=nav><ul class=nav-list><li class=nav-item><a class=pure-button href=https://github.com/rlupton20><i class="fa fa-github-alt"></i>Github</a></li><li class=nav-item><a class=pure-button href=https://rlupton20.github.io/index.xml><i class="fa fa-rss"></i>rss</a></li></ul></nav></div></div><div class="content pure-u-1 pure-u-md-3-4"><div><div class=posts><h1 class=content-subhead>18 Mar 2020, 19:32</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/floki/ class=post-title>Easy, reproducible, and shareable development environments</a><p class=post-meta></p></header><div class=post-description><p>Docker makes it easy to create container images containing the tools you need to work on a project. However this can be fiddly to use well in many circumstances. Here we will visit the normal approach of using a docker container for development environments, indicate some ways in which it gets complicated, and then introduce a solution, called <a href=https://github.com/Metaswitch/floki>floki</a> which greases the wheels and makes the whole process easier.</p><h1 id=creating-a-basic-build-environment-with-docker>Creating a basic build environment with Docker</h1><p>Let&rsquo;s imagine we have a little C project which we want to statically compile using musl libc. We might, in the K&amp;R tradition, have</p><pre><code class=language-C>#include &lt;stdio.h&gt;

int
main(int argc, char* argv[])
{
  printf(&quot;Hello, world\n&quot;);
  
  return 0;
}
</code></pre><p>in a file <code>main.c</code>, and a simple <code>Makefile</code></p><pre><code>.PHONY: clean

all:
      gcc -o main -static main.c

clean:
      rm main
</code></pre><p>To build against musl libc, it can be convenient to use a docker container built off of an alpine image as a base, where <code>make</code> and a C compiler have been installed. We can declare this in a <code>Dockerfile</code></p><pre><code>FROM alpine:latest

RUN apk update &amp;&amp; apk add alpine-sdk
</code></pre><p>(in practice, using the <code>latest</code> tag and running <code>apk update</code> is unlikely to be reproducible - you&rsquo;ll want to pin your image more precisely).</p><p>This can be built with</p><pre><code>$ docker build -t hello-world .
</code></pre><p>And we can mount our codebase at <code>/mnt</code> inside a container running this image with</p><pre><code>$ docker run --rm -it -v $(pwd):/mnt hello-world:latest
</code></pre><p>From here, you should be able to <code>cd /mnt</code> and run <code>make</code> to get a statically linked binary linked against musl libc.</p><p>Great! This is a fine way to get working with docker as a build environment. However, it&rsquo;s a bit of a pain to run the build and then run steps when the needs of the build container change. This is of course scriptable, but repeating this pattern across many codebases leads to a lot of copy-pasting of scripts. Furthermore, if you need additional settings for your docker container - additional volume mounts, docker-in-docker for testing with e.g. <code>docker-compose</code>, or forwarding of an SSH agent to authenticate with a <code>git</code> server, the scripting becomes more unwieldy, and harder to maintain across codebases.</p><p>Oftentimes, build environments are neglected, and even if developers are using docker containers for their build, they don&rsquo;t share anything to replicate that environment for other users. Figuring out what is needed to build a project is an unnecessary time sink.</p><h1 id=floki>floki</h1><p><code>floki</code> essentially lets you write what you want in a YAML file, and turns that into reality. It was created to solve the problems above, which I found across multiple microservice codebases. It&rsquo;s great for new developers wanting to get build environments, because they just need to run <code>floki</code> and they are good to go.</p><p>So how would the example above translate?</p><p>Well, we keep the <code>Dockerfile</code>, and then we create a file called <code>floki.yaml</code> in the root of our codebase:</p><pre><code>image:
  build:
    name: hello-world
    dockerfile: Dockerfile

mount: /mnt
    
init:
   - echo 'Welcome to the hello-world build container'
</code></pre><p>We can then simply run <code>floki</code> from a shell, and <code>floki</code> takes care of building the docker image, and dropping us into the shell in the mounted working directory. It even prints out the friendly greeting from the <code>init</code> section - in practice it&rsquo;s nice to print some basic usage instructions here, for example, instructions for how to build a project, or run tests.</p><h1 id=more-wins>More wins</h1><p>Although this seems small, the ergonomics are already much better. Regardless, <code>floki</code> gives us more for free.</p><h2 id=docker-in-docker>docker-in-docker</h2><p>If our docker container has the docker command line tools (or some other way to interact with a docker daemon), we can get docker-in-docker support by adding</p><pre><code>dind: true
</code></pre><p>to our <code>floki.yaml</code>.</p><h2 id=ssh-agent-forwarding>SSH agent forwarding</h2><p><code>floki</code> lets you forward your SSH agent. This can be useful if you want to pull libraries from a private <code>git</code> server for a build, or if you want to configure a dockerized environment for SSHing into virtual machines (maybe you want to run <code>fabric</code> or <code>ansible</code> from inside the container).</p><p>You can enable this by adding</p><pre><code>forward_ssh_agent: true
</code></pre><p>to your <code>floki.yaml</code>.</p><h2 id=build-caches-with-floki-volumes>Build-caches with <code>floki</code> volumes</h2><p>Losing cached build artifacts between runs of build containers is annoying, especially if you have to compile them from source. <code>floki</code> lets you attach volumes (which can even be shared among different containers) to use as a build cache.</p><p>Here is an example for caching Rust artifacts</p><pre><code>image: ekidd/rust-musl-builder
mount: /home/rust/src
forward_ssh_agent: true
shell: bash
volumes:
  registry:
    mount: /home/rust/registry
</code></pre><p>By default, each the volume is localised to a particular project (that is, the folder and filename for the <code>floki</code> configuration file). The <code>shared: true</code> key can be added to the <code>volume</code> key to use the same volume across all other projects with the same volume name (<code>registry</code> in the example above) and with the <code>shared</code> key set to true. In the example above, this would mean all rust containers with the <code>shared</code> <code>registry</code> volume will share the same volume. Combine this with a caching solution on the backing directory and you have a cross company build cache.</p><h1 id=conclusion>Conclusion</h1><p>Creating reproducible build environments makes reliable builds easier to achieve. <a href=https://github.com/Metaswitch/floki>floki</a> makes doing this more ergonomic, and lowers the barrier to doing so, and makes it easier to share with other developers.</p><p>There is more than just the above - check out <a href=https://github.com/Metaswitch/floki>the floki GitHub page for more</a>.</p></div></section><h1 class=content-subhead>29 Dec 2019, 20:19</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/overloaded-labels-in-haskell/ class=post-title>Overloaded Labels in Haskell - towards better record fields</a><p class=post-meta></p></header><div class=post-description><h1 id=introduction>Introduction</h1><p>Haskell is one of my (if not my) favourite language. Like all languages it has its warts, and one which I have always found particularly annoying is the fact that record names of data types can&rsquo;t be overloaded (they are just functions, after all). I haven&rsquo;t been writing as much Haskell as I would like lately, and certainly haven&rsquo;t been messing around with the more cutting edge type level functionality, but noticed that GHC 8.0 (which was released a while ago now), was release with some new language extensions which looked like they would allow record names to be overloaded, in some shape or form.</p><p>The GHC wiki, which purports to provide the necessary documentation to understand this, describes what the new language extensions are, but not really how you might go about using it. So I cooked up a small toy to show how I think they are meant to be used.</p><h1 id=a-short-example>A short example</h1><p>My toy example has two data types, a <code>User</code> data type, and an <code>Item</code> data type. Both of these have a field I want to call <code>name</code>. In order to be able define these two types, I need the <code>DuplicateRecordFields</code> extensions, otherwise GHC will complain. <code>OverloadedLabels</code> provides some syntactic sugar to use with the <code>IsLabel</code> type class, which brings the record syntax nearer to what one might expect. The other extensions are needed for the required type-level fu.</p><p>Here is a short working example - chuck it in a file called <code>OverloadedLabels.hs</code>,</p><pre><code class=language-haskell>{-# LANGUAGE DuplicateRecordFields #-}
{-# LANGUAGE OverloadedLabels #-}
{-# LANGUAGE DataKinds #-}
{-# LANGUAGE FlexibleInstances #-}
{-# LANGUAGE MultiParamTypeClasses #-}
module OverloadedLabels where

import GHC.OverloadedLabels (IsLabel(..))
 
data User = User { name :: String } deriving (Eq, Show)

data Item = Item { name :: String
                 , uid :: Integer } deriving (Eq, Show)

instance IsLabel &quot;name&quot; (Item -&gt; String) where
  fromLabel = name

instance IsLabel &quot;name&quot; (User -&gt; String) where
  fromLabel = name
</code></pre><p>and fire it up in <code>ghci</code> with the <code>OverloadedLabels</code> extension (so that we can use the extended syntax interactively).</p><pre><code>$ ghci -XOverloadedLabels OverloadedLabels.hs
GHCi, version 8.4.4: http://www.haskell.org/ghc/  :? for help
[1 of 1] Compiling OverloadedLabels ( OverloadedLabels.hs, interpreted )
Ok, one module loaded.
*OverloadedLabels&gt;
</code></pre><p>The first thing to note is that, even with type annotations, the <code>name</code> accessor can&rsquo;t be used directly:</p><pre><code>*OverloadedLabels&gt; (name :: User -&gt; String) $ User &quot;bob&quot;

&lt;interactive&gt;:4:2: error:
    Ambiguous occurrence ‘name’
    It could refer to either the field ‘name’,
                             defined at OverloadedLabels.hs:12:20
                          or the field ‘name’, defined at OverloadedLabels.hs:10:20
</code></pre><p>This would be the most ergonomic experience (albeit, not necessarily backward compatible). The <code>OverloadedLabels</code> extension gives a terse almost-ideal syntax for using <code>name</code> to access <code>name</code> fields:</p><pre><code>*OverloadedLabels&gt; #name $ User &quot;bob&quot; :: String
&quot;bob&quot;
*OverloadedLabels&gt; #name $ Item &quot;book&quot; 5 :: String
&quot;book&quot;
</code></pre><p>(The type hints here help resolve the correct <code>IsLabel</code> instance - in real-world usage type inference will probably do the magic here for you).</p><p>Cool!</p><h1 id=clarifying-each-extension>Clarifying each extension</h1><p>In this example, each extension is pretty straightforward</p><ul><li><code>DuplicateRecordFields</code> instructs the compiler to allow the same record accessor names to be defined for multiple data types.</li><li><code>OverloadedLabels</code> provides the <code>#</code> syntactic sugar. In the above, <code>#name</code> decodes to a <code>fromLabel</code> instance for the appropriate types.</li></ul><h1 id=some-observations>Some observations</h1><p>Notice how the <code>IsLabel</code> typeclass is about labelling the accessor function, and not the field of a record (in the example above we name the function <code>* -&gt; String</code> not <code>String</code>). Also note that there is nothing preventing you from overloading <code>name</code> even further - we can use it to give an accessor for the <code>Integer</code> element of the <code>Item</code> datatype above.</p><pre><code class=language-haskell>instance IsLabel &quot;name&quot; (Item -&gt; Integer) where
  fromLabel = uid
</code></pre><pre><code>*OverloadedLabels&gt; #name $ Item &quot;book&quot; 5 :: Integer
5
</code></pre><p>Nonetheless, <code>IsLabel</code> can be used to label more than just record accessors - it&rsquo;s much more generic.</p><p>Also note that the accessor <code>name</code> is distinct from <code>#name</code>, which decodes to a type-level <code>Symbol</code> <code>&quot;name&quot;</code> - they are completely different objects - the naming here shows intention, more than anything.</p><h1 id=looking-forward>Looking forward</h1><p>While this allows gives us overloaded record accessors, it&rsquo;s a shame about the boilerplate. Fortunately, work is being done to enable GHC to generate (or infer) the <code>IsLabel</code> instances by way of a <code>HasField</code> typeclass which is instantiated for each data type. Take a look at the work on magic type classes for more information. <code>HasField</code> has been merged into GHC 8.2, but without the typeclass inference for <code>IsLabel</code>. With that last piece in place, the <code>#</code> symbol should be usable with little to no boilerplate!</p></div></section><h1 class=content-subhead>26 Dec 2019, 18:35</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/getting-started-with-st/ class=post-title>Getting Started With ST - the simple terminal</a><p class=post-meta></p></header><div class=post-description><h1 id=introduction>Introduction</h1><p><code>st</code> is a <a href=https://st.suckless.org/>simple terminal emulator from suckless tools</a>. It provides the core features you need from a virtual terminal without being a bloated mess. While I like <code>urxvt</code>, <code>st</code> is smaller, simpler and a touch faster. Like most suckless tools, <code>st</code> provides a minimal feature set, with the expectation that users will patch in additional features as wanted, or compose <code>st</code> with other tools (e.g. <code>dmenu</code>) to provide a more complex experience. This approach may seem a bit spartan to many - editing C for configuration isn&rsquo;t the most friendly interface - but what you get is solid, easy to understand, and is very hackable. I use it on my systems because I like its minimalism.</p><h1 id=getting-the-source-and-building>Getting the source and building</h1><p>To build <code>st</code> you&rsquo;ll need a few libraries for building X applications, in particular <code>libX11</code>.
None of the following is surprising - clone the source, read the <code>README</code>, adjust as needed, build and install.</p><h2 id=getting-the-source-and-basic-build>Getting the source and basic build</h2><p>Clone the source code directly from suckless.</p><pre><code>$ git clone https://git.suckless.org/st
</code></pre><p>Change directory into the source tree</p><pre><code>cd st
</code></pre><p>At this point, you may want to checkout the latest release tag (at time of writing it&rsquo;s <code>0.8.2</code>) with</p><pre><code>git checkout 0.8.2
</code></pre><p>I&rsquo;m happy building straight off master.</p><p>A simple build can be done by running</p><pre><code>$ make st
</code></pre><p>and the binary is emitted to the source directory. It can be tested with</p><pre><code>$ ./st
</code></pre><p>This is useful for testing customizations without installing system wide.</p><h2 id=system-wide-installation>System-wide installation</h2><p>The built binary can be installed system wide using</p><pre><code>$ sudo make clean install
</code></pre><h2 id=user-installation>User installation</h2><p>Alternatively, a user installation can be done by editing <code>config.mk</code>, changing the <code>PREFIX</code> variable to, e.g. <code>~/.local/</code> (assuming <code>~/.local/bin</code> is on your path).</p><pre><code class=language-Makefile>PREFIX = ~/.local
</code></pre><p>then running</p><pre><code>$ make clean install
</code></pre><p>If you need manpages for <code>st</code>, then you will need to update your <code>MANPATH</code> to include <code>~/local/share/man</code>.
Be aware that the <code>st</code> manpage conflicts with the SCSI tape device manuals - you may want to rename the man page. Maybe you don&rsquo;t care.</p><p>You can also read the man pages by telling <code>man</code> about the local search path</p><pre><code>$ man -M ~/.local/share/man st
</code></pre><h1 id=customization>Customization</h1><p>Customization of <code>st</code> is usually done through editing the C files. I find it works pretty well out of the box (with <code>tmux</code> used from scrollback etc). Basic settings can be changed in the <code>config.h</code> configuration header file.</p><p>Further customization can be achieved by editing the C source code directly. The <code>st</code> webpage has a collection of <a href=https://st.suckless.org/patches/>patches</a> from other users which can be applied to add new features. I find the default setup pretty much good to go - all I do usually is tweak the font size a little in <code>config.h</code>.</p><p>A <code>git</code> branch is useful for managing a collection of customizations. Changes can be rebased onto newer (or older) <code>st</code> versions, and new patch files can be generated using <code>git diff</code>.</p></div></section><h1 class=content-subhead>19 Nov 2019, 00:26</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/debian-font-configuration/ class=post-title>Getting decent font rendering on stock Debian</a><p class=post-meta></p></header><div class=post-description><p>I recently converted one of my machines from a parabola installation to a Debian 10 system. I started from a text only interface - the bare minimum of packages - and installed the rest by hand. For reasons that aren&rsquo;t entirely clear, the default font rendering is pretty hideous. It took me a while to track down how to properly configure font rendering. Perhaps this isn&rsquo;t an issue for installs which include a desktop from the get go. If it is, maybe this can help. While I did this on Debian, there isn&rsquo;t much Debian specific - I&rsquo;ve opted for the text file editing approach to configuration instead of strange menu-driven or ncurses stuff. This allows me to version the configuration or do automation work later.</p><h1 id=the-very-short-version>The very short version</h1><p>Enter the following into <code>/home/user/.config/fontconfig/fonts.conf</code>.</p><pre><code class=language-xml>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;!DOCTYPE fontconfig SYSTEM &quot;fonts.dtd&quot;&gt;
&lt;fontconfig&gt;

  &lt;!-- Enable antialiasing for all fonts --&gt;
  &lt;match target=&quot;font&quot;&gt;
    &lt;edit mode=&quot;assign&quot; name=&quot;antialias&quot;&gt;
      &lt;bool&gt;true&lt;/bool&gt;
    &lt;/edit&gt;
  &lt;/match&gt;

&lt;/fontconfig&gt;
</code></pre><p>Restart an application (firefox, virtual terminal) to see the changes. For me, just adding anti-aliasing to font rendering made all the difference. There are more dials to tune, but this was enough to make the font rendering passable.</p><h1 id=beginning-the-art-and-craft-of-debugging-fonts>Beginning the art and craft of debugging fonts</h1><p>I don&rsquo;t know why fonts remain such a painful part of the linux experience. Perhaps it&rsquo;s just me, but figuring out what&rsquo;s going on, and how to configure the font rendering isn&rsquo;t at all obvious. As such, I thought I&rsquo;d make a list for my future self of tools to use to help determine what is going on.</p><ul><li><code>fc-conflist</code> lists all the files which are read to determine font configuration.</li><li><code>xterm</code> launched from a terminal usefully prints out some errors in font configuration (e.g. unrecognised entries). There ought to be a better way than this, but I don&rsquo;t know it (I discovered this by accident).</li><li><code>fc-cache</code> builds font information caches.</li><li><code>fc-list</code> lists all fonts on the system.</li></ul><p>Using these together with restarting a test application can help get the fonts to render as you would like.</p><p>I also noticed taking screenshots was well worthwhile, or at least doing a side-by-side comparison of different settings. I thought my settings had made one program render very strangely compared to previous settings, but direct comparison showed no difference! In fact, anti-aliasing was the only change I made where I could tell the difference in the font rendering (it&rsquo;s possible all other settings I tried were already set in the other configuration files). Now text doesn&rsquo;t look like total garbage.</p><p>At a future point, when I can find the will to do it, I&rsquo;ll tune the rendering further still, and expand these notes.</p></div></section><h1 class=content-subhead>30 Oct 2019, 12:21</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/y-combinator/ class=post-title>The Y combinator - understanding recursion without recursion</a><p class=post-meta></p></header><div class=post-description><h1 id=introduction>Introduction</h1><p>Recursion is central to functional programming, as a clearer alternative to loops as other control structures typical of imperative languages. Functional programming encourages programmers to study recursion in greater depths. I first encountered the Y combinator in the mind-bending penultimate chapter of the wonderful <em>The Little Schemer</em>, which explores recursion in great depth. In an effort to unbend my own mind on the subject, I decided to derive it for myself, so I could see how it worked, and gain an extra tool in dealing with recursion and closures.</p><blockquote><p>Do you now know why Y works? Read this chapter just one more time and you will.<br><em>(The Little Schemer)</em></p></blockquote><p>The Y combinator was discovered by Haskell Curry in the 1940s. It allows recursion to be captured without functions needing to reference themselves by name. It provides some insight into the nature of recursion in the lambda calculus (where nothing has a name), and also demonstrates the power of closures.</p><p>We will conduct our explorations mostly in scheme, because it&rsquo;s expressive, concise and elegant, but we also give examples in Haskell and JavaScript at the end. The Haskell version is ludicrously simple and clear (relying on lazy evaluation), while the JavaScript version mirrors the Scheme version.</p><h2 id=further-reading>Further reading</h2><p><em>The Little Schemer</em> (amazon <a href="https://www.amazon.co.uk/Little-Schemer-MIT-Press/dp/0262560992/ref=as_sl_pc_tf_til?tag=zigschots20-21&amp;linkCode=w00&amp;linkId=01845223831793ea377c7e652c3f8547&amp;creativeASIN=0262560992">uk</a>/<a href="https://www.amazon.com/Little-Schemer-Daniel-P-Friedman/dp/0262560992/ref=as_sl_pc_qf_sp_asin_til?tag=zigschots20-20&amp;linkCode=w00&amp;linkId=b4600a1821debb502f6423061932ea51&amp;creativeASIN=0262560992">us</a>) gives a great introduction to recursion, including a section on the Y combinator. The presentation here is a little different, since I wanted a more direct understanding of how the Y combinator worked.</p><h1 id=recursive-functions-as-fixed-points-of-higher-order-functions>Recursive functions as fixed points of (higher-order) functions</h1><p>The Y combinator allows the programmer to pass in a function which isn&rsquo;t explicitly recursive (doesn&rsquo;t reference itself by name), but describes a step in a recursive process with a continuation, and provides back a new function which recursively applies that step using itself as the continuation.</p><p>Let&rsquo;s start by making the term &ldquo;step in a recursive process with a continuation&rdquo; more concrete, and clarify how the Y combinator acts on these steps.</p><p>To give us something specific to think about, let&rsquo;s examine the factorial function. The classic recursive definition of factorial is expressed in Scheme as follows</p><pre><code class=language-scheme>(define (factorial n)
  (if (= n 0)
    1
    (* n (factorial (- n 1)))))
</code></pre><p>This definition references itself. We can view it as an equation in terms of <code>factorial</code>, however. In fact, we can define</p><pre><code class=language-scheme>(define (factorialize f)
  (lambda (n)
    (if (= n 0)
      1
      (* n (f (- n 1))))))
</code></pre><p>and observe that <code>(factorialize factorial)</code> (<code>factorialize</code> applied to the <code>factorial</code> function) is itself <code>factorial</code>. The formal way to say this is that <code>factorial</code> is a fixed-point of <code>factorialize</code>.</p><p>Its important to understand that <code>factorialize</code> operates on all functions from numbers to numbers. In terms of function, we can look at <code>factorialize</code> as doing a single step in the factorial function, and then, instead of recursing, handing off the remainder of the work to a continuation which is passed in as a parameter. This is what is meant by a &ldquo;step in a recursive process with a continuation&rdquo;. <code>factorialize</code> itself is not recursive - it hands the recursion over to some continuation which is passed in.</p><p>The Y combinator turns these recursive steps into full-blown recursive functions. Applied to <code>factorialize</code> it finds a fixed point (you can prove by induction that such a fixed point is necessarily the <code>factorial</code> function). This means we can define the factorial function by</p><pre><code class=language-scheme>(define factorial
  (Y factorialize))
</code></pre><p>where here, <code>Y</code> is the Y combinator. How does it do this? In effect it passes <code>factorialize</code> in as the continuation to <code>factorialize</code>, so that the same recursive step is applied over-and-over, until we reach the base case.</p><h1 id=deriving-the-y-combinator>Deriving the Y combinator</h1><h2 id=capturing-our-own-value>Capturing our own value</h2><p>The fixed point perspective is a useful starting point, because we want the Y combinator applied to <code>factorialize</code> to be an expression <code>expr</code> which satisfies</p><pre><code>expr = (factorialize expr)
</code></pre><p>One possible starting point is to ask, how can an expression capture it&rsquo;s own value? That is, can we write an expression, which, inside itself, has a handle on its own value.</p><p>The trick to doing this is to observe that applying the anonymous function <code>(lambda (f) (f f))</code> to a function allows a function to receive itself as an argument. If we feed this function another function, <code>(lambda (recur) ...)</code>, and try to evaluate it</p><pre><code class=language-scheme>((lambda (f) (f f))
  (lambda (recur)
    ...))
</code></pre><p>Then inside the inner lambda, <code>recur</code> will be bound to the <code>(lambda (recur) ...)</code>. But then <code>(recur recur)</code> is just the inner lambda <code>(lambda (recur) ...)</code> applied to itself, which is the value of the expression we&rsquo;re trying to evaluate (that might take a few reads!).</p><p>In other words, if we try to evaluate the following</p><pre><code class=language-scheme>((lambda (f) (f f))
  (lambda (recur)
    (recur recur)))
</code></pre><p>by applying the outer function, we get back to where started. If you try to evaluate this, it will just loop forever! In Haskell we could write this as</p><pre><code class=language-haskell>let x = x in x
</code></pre><p>Since we are looking for a function <code>exp</code> with value <code>(factorialize exp)</code>, and we know <code>(recur recur)</code> has value <code>exp</code> in the above, we can try inserting a call to factorialize:</p><pre><code class=language-scheme>((lambda (f) (f f))
  (lambda (recur)
    (factorialize (recur recur))))
</code></pre><p>By the same reasoning, if this has value <code>v</code>, then by applying the outer <code>lambda</code>, we see it also has value <code>(factorialize v)</code>. Great! We&rsquo;ve found a fixed point for <code>factorialize</code>, and hence this must be the <code>factorial</code> function. In fact, if we parameterize over <code>factorialize</code> then we have the (formal) Y combinator!</p><h2 id=making-it-run>Making it run</h2><p>What happens when we try and evaluate this? Firing up a Scheme interpreter and plugging it in</p><pre><code>((lambda (f) (f f))
 (lambda (recur)
  (factorialize (recur recur))))

;Aborting!: maximum recursion depth exceeded
</code></pre><p>Hmm. The issue here is that when trying to evaluate this procedure, <code>(recur recur)</code> has to be fully evaluated before a call to <code>factorialize</code> is made (scheme evaluates its arguments before calling functions). This means for our expression <code>exp</code> to be evaluated, <code>exp</code> (<code>(recur recur)</code>) must first be evaluated - this leads to an infinite loop!</p><p>To fix this, we want to delay the evaluation of <code>(recur recur)</code> until it is needed (in other words evaluate it lazily). We can do this with the aid of a lambda:</p><pre><code class=language-scheme>((lambda (f) (f f))
 (lambda (recur)
  (factorialize (lambda (x) ((recur recur) x)))))
</code></pre><p>Let&rsquo;s try it:</p><pre><code>(((lambda (f) (f f))
 (lambda (recur)
   (factorialize (lambda (x) ((recur recur) x))))) 0)

;Value: 1
</code></pre><pre><code>(((lambda (f) (f f))
 (lambda (recur)
   (factorialize (lambda (x) ((recur recur) x))))) 5)

;Value: 120
</code></pre><p>Looking good! Notice that none of this has anything to do with <code>factorialize</code>. We can parameterise and abstract:</p><pre><code class=language-scheme>(define (Y F)
  ((lambda (f) (f f))
   (lambda (recur)
     (F (lambda (x) ((recur recur) x))))))
</code></pre><p>Hello Y combinator!</p><h1 id=examples-of-the-y-combinator-in-action>Examples of the Y combinator in action</h1><p>We started with the factorial function, so that ought to work as expected:</p><pre><code class=language-scheme>(define factorial
  (Y
   (lambda (recur)
     (lambda (n)
       (if (= n 0)
           1
           (* n (recur (- n 1))))))))


(factorial 5)

;Value: 120
</code></pre><p>Another easy example is defining the length of a list:</p><pre><code class=language-scheme>(define length
  (Y
   (lambda (recur)
     (lambda (l)
       (if (null? l)
           0
           (+ 1 (recur (cdr l))))))))


(length '(1 2 3))

;Value: 3

</code></pre><p>Multiple calls to recur also work just fine:</p><pre><code class=language-scheme>(define fibonacci
  (Y
   (lambda (recur)
     (lambda (n)
       (cond 
        ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (recur (- n 1))
                 (recur (- n 2)))))))))
                 

(map fibonacci (list 0 1 2 3 4 5 6 7 8))

;Value: (0 1 1 2 3 5 8 13 21)
</code></pre><p>We can also use the Y combinator&rsquo;s definition to write recursive lambdas inline. To give a contrived example using length of lists:</p><pre><code>(map
  ((lambda (F)
     ((lambda (f) (f f))
      (lambda (recur)
        (F (lambda (x) ((recur recur) x))))))
   (lambda (recur)
     (lambda (l)
       (if (null? l)
           0
           (+ 1 (recur (cdr l)))))))

  '((1) (1 2) (1 2 3)))

;Value: (1 2 3)
</code></pre><h1 id=intuitions-about-y-as-a-limit>Intuitions about Y as a limit</h1><p>Let&rsquo;s try and get a different intuition for how Y works. Let&rsquo;s lean on our <code>factorial</code> and <code>factorialize</code> example some more.</p><p>One intuitive way to get <code>factorial</code> out of <code>factorialize</code>, is to pass <code>factorialize</code> something like <code>factorialize</code> as it&rsquo;s argument. In fact, each of the following gets closer and closer to <code>factorial</code></p><pre><code class=language-scheme>(factorialize factorialize)                                ; Evaluates correctly for 0
(factorialize (factorialize factorialize))                 ; Evaluates correctly for 0, 1
(factorialize (factorialize (factorialize factorialize)))  ; Evaluates for correctly 0, 1, 2
...
</code></pre><p>One can think of <code>factorial</code> as being something like</p><pre><code class=language-scheme>(factorialize (factorialize (factorialize ...)))
</code></pre><p>Notice that to evaluate <code>factorial</code> on a given number, we only need finitely many of these calls to <code>factorialize</code>.</p><p>In fact, if we expand, for example, <code>((Y factorialize 3))</code> we get</p><pre><code class=language-scheme>(factorialize
  (factorialize
    (factorialize
      ((factorialize _) 0))))
</code></pre><p>where the <code>_</code> represents a <code>lambda</code> which is never evaluated.</p><h1 id=in-some-other-languages>In some other languages</h1><p>The Y combinator is not restricted to Lisps. Let&rsquo;s give examples of the Y combinator in Haskell and JavaScript.</p><h2 id=the-y-combinator-in-haskell>The Y combinator in Haskell</h2><p>Lazy evaluation means that in Haskell we don&rsquo;t need to work so hard, and we can just write down what i means to be a fixed point</p><pre><code class=language-haskell>y :: (a -&gt; a) -&gt; a
y f = let g = f g in g

factorial :: Integer -&gt; Integer
factorial = y factorialize
  where
    factorialize _ 0 = 1
    factorialize recur n = n * recur (n - 1)
</code></pre><p>This to me seems something close to magic, even though in many ways its simpler to think about than the Scheme version. <code>y</code> is more often named <code>fix</code> in the Haskell community, presumably because it is a definition by equation of a fixed-point. Haskell really is quite beautiful.</p><h2 id=the-y-combinator-in-javascript>The Y combinator in JavaScript</h2><p>JavaScript is not so beautiful. Lambdas and functions might be the only sensible parts of JavaScript, but that&rsquo;s an extraordinarily powerful part all the same. Another grace is that you can even try this snippet in the developer console of your browser.</p><pre><code class=language-javascript>const y = (f) =&gt; ((g) =&gt; g(g))(
    (recur) =&gt; f((x) =&gt; recur(recur)(x))
);

const factorialize = (recur) =&gt; (n) =&gt; n == 0 ? 1 : n * recur (n - 1);
const factorial = y(factorialize);
</code></pre><h1 id=conclusions>Conclusions</h1><p>Lambdas really are way more powerful than you would at first think! I found understanding how to derive the Y combinator gives me a new way to think. There really are good reasons why functional programming reveres the lambda so much - they are the Jedi weapon par excellence.</p><p>I can imagine many folks would balk at the code for the y combinator - it&rsquo;s hard to see what it does at a glance. It&rsquo;s nonetheless wonderfully abstract, and can be understood by its properties. Nonetheless, explicit recursion is probably clearer.</p></div></section><h1 class=content-subhead>25 Sep 2017, 16:00</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/2017-09-25-libre-rate-your-nixos/ class=post-title>Libre-rate your NixOS</a><p class=post-meta></p></header><div class=post-description><p>NixOS isn&rsquo;t a libre distribution by any means, but it comes close, and maintains a clear distinction between free and non-free packages (and in fact, different license types). This makes it possible to configure the system to exclude non-free packages, and with the addition of a libre kernel, allows us to turn NixOS into a libre platform. Of course, this isn&rsquo;t the same as leveraging an FSF endorsed distribution, but for those who are happy to maintain and take responsibility for the software running on their systems, it&rsquo;s as good. In fact, it&rsquo;s a little strange that the process of deblobbing normal systems isn&rsquo;t better documented and more widely done, after all, this is exactly what a libre distribution typically is. If you want a libre system out of the box, with nix-y functionality, GuixSD is also worth a look, but I really like NixOS, and I thought it worth the effort to libre-up.</p><p>By default, most non-free packages can&rsquo;t be installed on nixos without explicitly allowing unfree packages. There are a couple of places however where non-free software can be installed. The first is in the standard linux kernel, so our first job is to rebase our system on top of a libre linux build. NixOS does allows packages with the license type <code>unfreeRedistributableFirmware</code>, so the remainder of the work consists of blacklisting this license type.</p><h1 id=installing-a-libre-kernel>Installing a libre kernel</h1><p>The default linux kernel comes with all the binary blobs typically packaged with the linux kernel. NixoOS makes it easy to specify a custom kernel in <code>/etc/nixos/configuration.nix</code>.</p><p>There are three stages to installing a custom kernel build:
- Generate/obtain a kernel build configuration file
- Write the build expression into <code>configuration.nix</code>
- Testing</p><p>Nix will take care of building and installing the kernel for us. It also makes it trivial to reproduce once we&rsquo;ve got the setup we want. Upgrades can be achieved just by updating the source package being pulled.</p><p>Building a kernel takes a little time, so if this is being done on a lot of machines (and once you&rsquo;ve got it working as you like), you may want to set up a custom repository and binary cache for your built kernel, and use this in your <code>configuration.nix</code>. <a href=http://sandervanderburg.blogspot.co.uk/2016/10/push-and-pull-deployment-of-nix-packages.html>This article</a> should help with this, and provide other options for deployment.</p><h2 id=obtaining-your-current-configuration>Obtaining your current configuration</h2><p>We can obtain the configuration file used to build the current kernel using <code>zcat /proc/config.gz</code>. Let&rsquo;s store this in a file alongside <code>configuration.nix</code> and use it to build our libre kernel.</p><pre><code class=language-bash>$ zcat /proc/config.gz | sudo tee /etc/nixos/kernel.config
</code></pre><p>At a later point you could customize this file to adjust the kernel to your needs, or run the configuration tools bundled with the libre kernel to generate a configuration file completely customized to your needs. The above approach however will do to get started.</p><h2 id=specifying-our-new-kernel>Specifying our new kernel</h2><p>Nix will take care of building our kernel properly. We just need to provide enough details in <code>configuration.nix</code>. The following addition to <code>configuration.nix</code> provides all we need to build the 4.12.10 linux-libre kernel in NixOS.</p><pre><code class=language-nix>boot.kernelPackages = pkgs.linuxPackages_custom
  version = &quot;4.12.10-gnu&quot;;
  src = pkgs.fetchurl {
    url = &quot;http://www.linux-libre.fsfla.org/pub/linux-libre/releases/4.12.10-gnu/linux-libre-4.12.10-gnu.tar.xz&quot;;
    sha256 = &quot;122a457b0def2050378359641cce341c4d5f3f3dc70d9c55d58ac82ccfaf361b&quot;;
  };
  configfile = /etc/nixos/kernel.config;
}; 
</code></pre><h2 id=building-and-testing>Building and testing</h2><p>Run <code>nixos-rebuild switch</code> to instantiate your new configuration. You can try out your new kernel and test it works easily, and if there are problems boot into the old working kernel from the bootloader (another nix win). You can roll back to your old configuration with <code>nixos-rebuild switch --rollback</code>.</p><h1 id=blacklisting-unwanted-licenses>Blacklisting unwanted licenses</h1><p><code>nixpkgs</code> can be configured to blacklist certain license types. The <a href=https://github.com/NixOS/nixpkgs/blob/master/lib/licenses.nix>license definition file</a> lists all the licenses used in all the packages in nix. Anything with <code>free = false;</code> is recognized as a non-free package by nix, and can&rsquo;t be installed unless non-free packages are explicitly enabled. However, there are non-free licenses without this label. <code>unfreeRedistributableFirmware</code> is non-free yet doesn&rsquo;t have this label. To help avoid inadvertantly installing these kinds of packages, we need to blacklist this license (along with any others we want to avoid).</p><h2 id=system-level>System level</h2><p>The following snippet, added to <code>configuration.nix</code> will do the job.</p><pre><code>{ config, pkgs, lib, ... }:
{

  . 
  .
  .

# Block any unfree firmware (which isn't in the kernel)
  nixpkgs.config = {
    blacklistedLicenses = with lib.licenses; [
      unfreeRedistributableFirmware
    ];
  };

  .
  .
  .
};
</code></pre><p>It&rsquo;s also possible to specify a license whitelist, with the option <code>whitelistedLicenses</code>.</p><h2 id=user-level>User level</h2><p><code>nixpkgs</code> configuration at the system level isn&rsquo;t reflected for the users, so users will still by default be able to install non-free packages. User <code>nixpkgs</code> need to be configured separately. At present, the best way to do this is to add</p><pre><code>{
  blacklistedLicenses = with stdenv.lib.licenses; [
	unfreeRedistributableFirmware
  ];
}
</code></pre><p>to <code>~/.config/nixpkgs/config.nix</code>. The <a href=https://nixos.org/nixpkgs/manual/#chap-packageconfig>nixpkgs manual</a> contains information here that&rsquo;s useful.</p><p>If you use a manifest to install packages, you can add these configuration options to your import of <code>nixpkgs</code>. For example:</p><pre><code>  # Define pkgs as &lt;nixpkgs&gt; with some licenses
  # blacklisted
  pkgs = import &lt;nixpkgs&gt; {
    config = {
      blacklistedLicenses = with _licenses; [
        unfreeRedistributableFirmware
      ];
    };
  };
</code></pre><p>Currently, there doesn&rsquo;t seem to be a way to add a system wide default for user nixpkgs configuration in the absence of an explicit configuration file, which is unfortunate. This works reasonably, in the meantime, and since firmware is the only non-free software available to users by default, is not as bad as it might seem.</p></div></section><h1 class=content-subhead>11 Sep 2017, 16:00</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/2017-09-11-lightweight-screenshots-in-xmonad/ class=post-title>Lightweight screenshots in Xmonad</a><p class=post-meta></p></header><div class=post-description><h2 id=introduction>Introduction</h2><p>Xmonad does not come with any kind of screenshot tool (or anything at all much, which in my view is a good thing - what it does do it does well). I didn&rsquo;t want a heavyweight system (something taken from GNOME or XFCE), but wanted some flexibility still. I made a little script which straps together <code>rofi</code>, <code>slop</code>, <code>maim</code> and <code>xclip</code> to provide a lightweight and flexible screenshotting tool. I&rsquo;m posting it here for anyone who is looking for something similar. Add a keybinding in <code>xmonad</code> and off you go! Of course, this will work perfectly well with other window managers too.</p><p>I wanted to be able to do a combination of the following things
1. Capture the whole screen
2. Capture just a section of the screen
3. Possibly capture to clipboard
4. Possibly capture to file
selectable quickly and easily from some kind of popup menu.</p><p>I decided to bind this script to <code>Mod-PrintScr</code>, with <code>PrintScr</code> bound to <code>maim -s -c 1,0,0,0.6 --format png /dev/stdout | tee ~/.screenshots/$(date +%F-%T).png | xclip -selection clipboard -t image/png -i</code> (capture selection to file and clipboard), a default of sorts.</p><h2 id=the-script-explained>The script explained</h2><p>The script is presented below. It is also available <a href=https://github.com/rlupton20/dotfiles/blob/master/scripts/super-screenshot.sh>here</a>. I imagine most people would want to modify it/rewrite it/use it as a basis for their own systems. Chances are, if you like using a tiler, you long lost interest in keeping to &ldquo;sensible defaults&rdquo;. Tweak away!</p><p><code>maim</code> is the main tool here for making screenshots. It can use <code>slop</code> in the background to do selections. <code>xclip</code> provides a way to get captures onto the clipboard. I wanted several options to be selectable when making a screenshot, so I encoded these options in a slightly horrible way into the script (see <code>OPTIONS</code>). The script breaks these down into actual option names that can be fed to <code>rofi</code> (a <code>dmenu</code> like tool - you could use <code>dmenu</code>) using fairly standard *nix sorcery, then uses the selection to extract the parameters from <code>OPTIONS</code> before making the screenshot.</p><p>We use <code>/dev/null</code> as a file when we don&rsquo;t want to actually save to file, and when we do, we create a new file in <code>SCREENSHOT_DIR</code> (with a datestamp) to store the capture in. When we don&rsquo;t want to save to clipboard, we pipe the capture into <code>xclip -h</code>, the help command for <code>xclip</code>. Massive hack, but it works.</p><h2 id=source>Source</h2><pre><code class=language-bash>#!/usr/bin/env bash

# DEPENDENCIES
# rofi, maim, slop, xclip

SCREENSHOT_DIR=~/.screenshots

# Options are separated by ;, with each field separated by :
# FIELD 0: name
# FIELD 1: maim switches
# FIELD 2: save to file
# FIELD 3: put on clipboard
OPTIONS='select:&quot;-c 1,0,0,0.6 -s&quot;:y:y;window:&quot;-c 1,0,0,0.6 -st 9999999&quot;:y:y;screen:&quot;&quot;:y:y;clip:&quot;-c 1,0,0,0.6 -s&quot;:n:y'

function get_maim_switches {
    echo $(echo $OPTIONS | tr ';' '\n' | grep ^${1} | awk -F ':' '{print $2}' | xargs echo)
}

function get_save {
    echo $(echo $OPTIONS | tr ';' '\n' | grep ^${1} | awk -F ':' '{print $3}' | xargs echo)
}

function get_clip {
    echo $(echo $OPTIONS | tr ';' '\n' | grep ^${1} | awk -F ':' '{print $4}' | xargs echo)
}


# Get user choice
CHOICE=$(echo $OPTIONS | tr ';' '\n' | awk -F ':' '{print $1}' | rofi -dmenu)

# Extract maim switches
MAIM_SWITCHES=$(get_maim_switches $CHOICE)

# Determine where to save the screenshot (possibly /dev/null)
TO_SAVE=$(get_save $CHOICE)
if [[ $TO_SAVE == y ]]
then
    SAVE_FILE=${SCREENSHOT_DIR}/$(date +%F-%T).png;
else
    SAVE_FILE=/dev/null
fi

# Determine whether to add to clipboard
TO_CLIP=$(get_clip $CHOICE)
if [[ $TO_CLIP == y ]]
then
    CLIP=&quot;-selection clipboard -t image/png -i&quot;
else
    CLIP=&quot;-h&quot; # Hack hack hack (pipe into help)
fi

# Do the screenshot
maim $MAIM_SWITCHES --format png /dev/stdout | tee $SAVE_FILE | xclip $CLIP
</code></pre></div></section><h1 class=content-subhead>23 Oct 2015, 16:00</h1><section class=post><header class=post-header><a href=https://rlupton20.github.io/posts/2015-10-23-booting-dragonfly-bsd-on-a-gpt-drive/ class=post-title>Booting DragonFly BSD with HAMMER on a GPT drive</a><p class=post-meta></p></header><div class=post-description><p>Here I’ll outline how I managed to get DragonFly BSD to boot from a single slice (Linux: partition) by chainloading the DragonFly bootloader boot1.</p><p>Note: for clarity’s sake, I’ll stick to the BSD terminology here. Slice refers to what Linux would dub a partition, and partition refers to a Linux “partition of a partition”. Linux’s <code>sda1</code> would therefore be slice <code>0</code> of disk <code>sda</code> (BSD counts from <code>0</code>), which on my BSD system is denoted <code>da0s0</code> (disk 0 slice 0 – first disk first slice).</p><h1 id=introduction>Introduction</h1><p>So first a little background. DragonFly BSD comes with a simple installer that works very well if your disk has an MBR partition table, or takes up the entire disk. The kernel is GPT compatible but the bootloader is not (inspection of the boot1 source code reveals it is exclusively MBR based). This need not be a problem if DragonFly is your only system, or you’re happy with MBR and DragonFly’s boot0 bootloader.</p><p>However, GPT offers many advantages, especially if you would like to dual boot alongside a linux installation, with plenty of slices. I wanted to dual boot alongside Arch linux, and bootload with GRUB2. This is what I’ll outline below.</p><p>One straightforward way to get this to work is to accept UFS partitions for DragonFly, loading the DragonFly kernel directly using GRUB. However, one of the attractions of DragonFly is its filesystem HAMMER, and unfortunately, unlike UFS, GRUB does not understand HAMMER.</p><p>The automatic installer installs DragonFly to one slice with three partitions. A small boot partition of type UFS, a swap partition, and the rest of type HAMMER. HAMMER allows for a series of pseudofilesystems, which incorporate the classic UNIX <code>/var</code>, <code>/usr</code> <code>/home</code> (and so on). This is the setup I wanted to achieve. However, the automatic installer doesn’t work with GPT format partition tables.</p><h2 id=proceed-with-installations>Proceed with installations</h2><p>First I installed Arch. The Arch documentation is good and suffices for the install. Its worth noting that despite using GPT, my system was running a BIOS, and not the more modern UEFI. I haven’t tested this with UEFI, and I don’t have a machine to try it with (which I’m willing to risk). Arch is easy to use to partition the drive with GPT, and a small (1MB) partition can be added at the start to install GRUB to for BIOS/GPT compatibility. The Arch documentation makes it clear how to do this. Of course, leave space for the DragonFly installation. I left ~70GB at the end of the drive.</p><p>Next install DragonFly. This must proceed manually, because the automatic installer won’t work for GPT. An invaluable guide which I initially overlooked is the readme file. Drop a directory (cd ..) and then you’ll find it – more README. This gives you a guide to manual installation. This and reading the man files ought to get you through the install, but here are a few notes. The entire process is not particularly complicated, and is not unlike installing Arch. There are a few differences, and its worth reading around the process a bit to familiarise yourself.</p><p>Add your DragonFly slice where you want it using the gpt tool (“man gpt” for details). You might need to feed it the start block (and possibly other parameters) to get it in the right place, because with GPT the first bit of free space is a tiny slot at the start of the disk. You just need one slice. Partitions of this will do the rest.</p><p>My DragonFly slice was the sixth GPT slice, so DragonFly names that da0s5. I’ll use this below. Adjust as necessary for your setup.</p><p>Don’t install <code>boot0</code> (no <code>boot0cfg</code> commands!), but do install bootblocks to the slice with:</p><pre><code>disklabel64 -B da0s5
</code></pre><p>This installs boot1/boot2 to the start of the slice. This is essential for chainloading, because GRUB will pass control to these boot blocks.</p><p>The disklabel was set to mimic that of the automatic installer, an <code>a</code> partition mounted <code>/boot</code> of type <code>UFS</code> (in the label BSD4.2), <code>b</code> of type swap, and <code>d</code> of type HAMMER, mounted as <code>/</code>. I essentially mimicked the arrangement found here: <a href=https://www.dragonflybsd.org/docs/newhandbook/environmentquickstart/#index2h2>https://www.dragonflybsd.org/docs/newhandbook/environmentquickstart/#index2h2</a>. The README file and disklabel manual should suffice to set this up.</p><p>Then format your partitions, mount them (as per README), and create the pseudofilesystems (PFSs), and mount them. cpdup everything in to place and tidy up.</p><p>Editing the example fstab file proved to be hassle with a tempermental vi, so I wrote one from scratch, mimicking that displayed in: <a href=https://www.dragonflybsd.org/docs/newhandbook/environmentquickstart/#index2h2>https://www.dragonflybsd.org/docs/newhandbook/environmentquickstart/#index2h2</a> (look for the <code>cat /etc/fstab</code> output – personally, however, I chose to softlink <code>/var/tmp</code> to <code>/tmp</code> also – the README here has a mistake, it links <code>/mnt/var/tmp</code> to <code>/tmp</code> instead of <code>/mnt/tmp</code> – this would create a link to the install media!).</p><p>The instructions will ask you to reboot. You can if you like. It is easy to boot back in to the install media and make the changes to get the system to boot. You won’t need drives mounted. One thing you might like to do is attempt chainloading in the current state (use the GRUB configuration detailed below), and confirm you get “Boot Error” as your error message. The following trick will fix this.</p><p>Tricking <code>boot1</code> – making your system boot</p><p>Now for the trick. If we were to chainload <code>(hd0, gpt6)</code>, which is GRUBs view of <code>da0s5</code>, we would get a “Boot Error” from <code>boot1</code>. This is because <code>boot1</code> looks for an MBR, and then looks for a BSD partition, from which it tries to boot. At the moment it won’t find DragonFly, because its slice is recorded in the GPT, which <code>boot1</code> does not understand.</p><p>However, if <code>boot1</code> was finding no MBR, it would return a “Read Error” (one needs to read the source code to discover this). So <code>boot1</code> must find an MBR. Where? In fact GPT specifies the existence of a “Protective MBR” for compatibility with MBR and BIOS systems. This is what <code>boot1</code> finds. You can view this (from the install media) with:</p><p><code>fdisk da0</code></p><p>This should show you the contents of the protective MBR, and it should show you the slice one is the entire disk, and the rest (2-4) are unused. This is so MBR systems do not think there is free space on the disk, when in actual fact GPT is managing it. The protective MBR of course occupies the same position on the disk as a normal MBR.</p><p><code>boot1</code> needs no more information than where to find DragonFly. Furthermore, <code>boot2</code> makes use of the disklabel, and doesn’t use the information which <code>boot1</code> gathers from the MBR, so we can write entries to the protective MBR without fear of the effect of these entries propagating too far. There is also nothing to stop us writing overlapping entries to this MBR either, using fdisk for example. So what we do is add a new entry to the protective MBR, which points to the <code>da0s5</code>, so that <code>boot1</code> can find it, and begin booting the rest of the system.</p><p>First run <code>gpt show da0</code>, and note down the start block and size (in blocks) of your DragonFly slice. Now run “fdisk -u da0”, leaving the first slice as is, but updating the second slice to be of type <code>165</code> (BSD’s type, and the one boot1 is looking for), and enter the start block you noted down, and also the size. Leave 3 and 4 unaltered and write this to the table. You can now chainload!</p><p>With this modification, <code>boot1</code> reads the protective MBR and finds an entry pointing to DragonFly (as if DragonFly were installed on a genuine MBR). This is enough to kickstart the system. Since the kernel has GPT compatibility, it sees the DragonFly partition as da0s5 as it should on a genuine GPT system. In fact, once boot1 has done its work, the rest of the system loads as if it were booted directly from the GPT format partition table.</p><p>Of course, if the GPT slice for DragonFly is moved, the protective MBR also requires updating. GPT compatibility of the bootloader is a much more desirable solution, but this is a simple and usable workaround for now. luxh on #dragonflybsd has pointed out that the tool “gptsync” can be used to help synchronise entries from the GPT with the MBR. Presumably, other people have used similar tricks elsewhere!</p><p>GRUB2 configuration</p><p>Just to be clear, my GRUB configuration file (<code>/etc/grub.d/40_custom</code>), has as entry</p><pre><code>menuentry “DragonFly BSD” {

setroot=(hd0,gpt6)

chainloader +1

}
</code></pre><p>A standard chainloader configuration. Install with <code>grub-mkconfig -o /boot/grub/grub.cfg</code>, from linux, or wherever it’s installed (<code>update-grub</code> if you are using *buntu).</p><h2 id=acknowlegments>Acknowlegments</h2><p>Thanks goes to the members of the #dragonflybsd irc channel for helping me eliminate possible causes of booting issues, providing insight into the current limitations of the boot system, and providing some encouragement for finding this solution.</p></div></section></div><div class=footer><div class="pure-menu pure-menu-horizontal pure-menu-open"><ul><li>Powered by <a class=hugo href=https://gohugo.io/ target=_blank>hugo</a></li></ul></div></div><script src=https://rlupton20.github.io/js/all.min.js></script></div></div></div><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-109154579-1','auto');ga('send','pageview');</script></body></html>